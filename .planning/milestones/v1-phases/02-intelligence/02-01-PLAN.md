---
phase: 02-intelligence
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/embeddings/embedder.ts
  - src/embeddings/index-manager.ts
  - src/embeddings/search.ts
  - src/engine/blackboard.ts
  - src/engine/decisions.ts
  - src/server.ts
  - test/embedder.test.ts
  - test/index-manager.test.ts
  - test/search.test.ts
  - package.json
autonomous: true
requirements:
  - EMBD-01
  - EMBD-02
  - EMBD-03
  - EMBD-04
  - BLKB-03

must_haves:
  truths:
    - "Agent can search blackboard entries by natural language query and get semantically relevant results"
    - "If ONNX runtime fails to load, server continues working with keyword-based search fallback"
    - "Embedding model is only loaded on first embedding operation, never at server startup"
    - "Every new blackboard entry and decision gets an embedding generated"
  artifacts:
    - path: "src/embeddings/embedder.ts"
      provides: "Lazy-loaded singleton embedding pipeline using @huggingface/transformers"
      exports: ["Embedder"]
    - path: "src/embeddings/index-manager.ts"
      provides: "CRUD for JSON-based embedding indexes in .twining/embeddings/"
      exports: ["IndexManager"]
    - path: "src/embeddings/search.ts"
      provides: "Cosine similarity search with keyword fallback"
      exports: ["SearchEngine"]
    - path: "test/embedder.test.ts"
      provides: "Embedder unit tests including fallback behavior"
    - path: "test/index-manager.test.ts"
      provides: "Index manager CRUD tests"
    - path: "test/search.test.ts"
      provides: "Search tests for both semantic and keyword modes"
  key_links:
    - from: "src/embeddings/embedder.ts"
      to: "@huggingface/transformers"
      via: "pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2')"
      pattern: "pipeline.*feature-extraction"
    - from: "src/embeddings/search.ts"
      to: "src/embeddings/embedder.ts"
      via: "Embedder.embed() for query vector"
      pattern: "embedder.*embed"
    - from: "src/embeddings/search.ts"
      to: "src/embeddings/index-manager.ts"
      via: "IndexManager.load() for stored vectors"
      pattern: "indexManager.*load"
    - from: "src/engine/blackboard.ts"
      to: "src/embeddings/embedder.ts"
      via: "Generate embedding on post()"
      pattern: "embedder.*embed"
    - from: "src/engine/decisions.ts"
      to: "src/embeddings/embedder.ts"
      via: "Generate embedding on decide()"
      pattern: "embedder.*embed"
---

<objective>
Build the embeddings layer: lazy-loaded ONNX embedder, JSON-based embedding index manager, cosine similarity search with keyword fallback, and wire embedding generation into existing blackboard/decision engines.

Purpose: Enable semantic search across all stored data (BLKB-03) with graceful fallback when ONNX is unavailable (EMBD-03). This is the foundation that the context assembler (Plan 02) builds upon.
Output: `src/embeddings/` module with embedder, index-manager, search; updated engines with embedding hooks; `twining_query` tool upgraded with semantic search.
</objective>

<execution_context>
@/Users/dave/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dave/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@TWINING-DESIGN-SPEC.md
@src/utils/types.ts
@src/storage/blackboard-store.ts
@src/storage/decision-store.ts
@src/storage/file-store.ts
@src/engine/blackboard.ts
@src/engine/decisions.ts
@src/server.ts
@src/tools/blackboard-tools.ts
@.planning/phases/02-intelligence/02-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Embedder, index manager, and search engine</name>
  <files>
    src/embeddings/embedder.ts
    src/embeddings/index-manager.ts
    src/embeddings/search.ts
    test/embedder.test.ts
    test/index-manager.test.ts
    test/search.test.ts
    package.json
  </files>
  <action>
    **Install dependency:**
    ```bash
    npm install @huggingface/transformers
    ```

    **Create `src/embeddings/embedder.ts`** — Lazy-loaded singleton embedding pipeline:
    - Singleton class `Embedder` with `getInstance()` static method
    - `embed(text: string): Promise<number[] | null>` — returns 384-dim vector or null if fallback mode
    - `embedBatch(texts: string[]): Promise<(number[] | null)[]>` — batch embedding for efficiency
    - `isFallbackMode(): boolean` — reports whether ONNX failed and we're in keyword-only mode
    - Uses `@huggingface/transformers` `pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2')` with `{ pooling: 'mean', normalize: true }`
    - Set `env.cacheDir` to `path.join(twiningDir, 'models')` for model cache within .twining/
    - Lazy initialization: pipeline is NOT created until first `embed()` call
    - Uses a single `initPromise` to prevent concurrent initialization
    - On ANY error during pipeline creation, set `fallbackMode = true` permanently, log warning, never throw
    - On embedding error for individual texts, return null silently (don't crash, don't enter fallback for transient errors)
    - Constructor takes `twiningDir: string` parameter (NOT singleton for testing; provide `static getInstance(twiningDir)` for production use)

    **Create `src/embeddings/index-manager.ts`** — Embedding index CRUD:
    - Class `IndexManager` with constructor taking `twiningDir: string`
    - Interface `EmbeddingIndex` matching spec section 5.3: `{ model: string, dimension: number, entries: { id: string, vector: number[] }[] }`
    - `load(indexName: 'blackboard' | 'decisions'): Promise<EmbeddingIndex>` — reads `.twining/embeddings/{indexName}.index` JSON, returns empty index if file doesn't exist
    - `save(indexName: 'blackboard' | 'decisions', index: EmbeddingIndex): Promise<void>` — writes index JSON atomically with `proper-lockfile`
    - `addEntry(indexName: 'blackboard' | 'decisions', id: string, vector: number[]): Promise<void>` — load, append, save
    - `removeEntries(indexName: 'blackboard' | 'decisions', ids: string[]): Promise<void>` — load, filter out, save
    - `getVector(indexName: 'blackboard' | 'decisions', id: string): Promise<number[] | null>` — quick lookup
    - Ensure `.twining/embeddings/` directory is created if it doesn't exist
    - Use `proper-lockfile` for concurrent write safety (same pattern as DecisionStore)

    **Create `src/embeddings/search.ts`** — Search with cosine similarity and keyword fallback:
    - Class `SearchEngine` with constructor taking `embedder: Embedder, indexManager: IndexManager`
    - `searchBlackboard(query: string, entries: BlackboardEntry[], options?: { entry_types?: string[], limit?: number }): Promise<{ entry: BlackboardEntry, relevance: number }[]>`
      - If embedder is NOT in fallback mode: embed query, load blackboard index, compute cosine similarity (dot product for normalized vectors), filter by entry_types if specified, sort by score descending, return top `limit` (default 10)
      - If embedder IS in fallback mode: call `keywordSearch()` instead
      - Include a `fallback_mode: boolean` field in results so callers know
    - `searchDecisions(query: string, decisions: Decision[], options?: { limit?: number }): Promise<{ decision: Decision, relevance: number }[]>`
      - Same pattern but for decisions index
    - Private `keywordSearch(query: string, items: { id: string, text: string }[], limit: number): { id: string, score: number }[]`
      - Split query into lowercase terms
      - For each item, count term matches using substring includes
      - Score: sum of `log(1 + occurrences)` per term, divided by query term count
      - Filter to score > 0, sort descending, return top limit
    - Private `cosineSimilarity(a: number[], b: number[]): number`
      - Dot product for pre-normalized vectors: `sum += a[i] * b[i]`
      - Use a simple for-loop (faster than reduce for 384-dim vectors)

    **Tests:**

    `test/embedder.test.ts`:
    - Test that `Embedder` is not initialized until first `embed()` call (lazy)
    - Test that when ONNX fails (mock pipeline to throw), embedder enters fallback mode and returns null
    - Test `isFallbackMode()` returns true after failure
    - Test that concurrent `embed()` calls during init don't create multiple pipelines
    - NOTE: Skip actual ONNX tests in CI (they require model download). Use a `SKIP_ONNX` env var. Write tests that mock the pipeline for unit testing.

    `test/index-manager.test.ts` (use temp directories via vitest):
    - Test `load()` returns empty index when file doesn't exist
    - Test `addEntry()` + `load()` round-trip
    - Test `removeEntries()` removes correct entries
    - Test `getVector()` returns correct vector or null
    - Test concurrent `addEntry()` calls don't corrupt the index (use Promise.all)

    `test/search.test.ts`:
    - Test `keywordSearch` with known data (exact matches, partial matches, no matches)
    - Test `searchBlackboard` in fallback mode uses keyword search
    - Test `cosineSimilarity` with known vectors (e.g., identical = 1.0, orthogonal = 0.0)
    - Test `searchBlackboard` with mock embedder (provide fixed vectors, verify ranking)
    - Test limit parameter works correctly
    - Test entry_types filter works
  </action>
  <verify>
    ```bash
    npm test -- --run test/embedder.test.ts test/index-manager.test.ts test/search.test.ts
    ```
    All tests pass. TypeScript compiles without errors: `npx tsc --noEmit`
  </verify>
  <done>
    Embedder lazy-loads ONNX pipeline on first use, falls back gracefully on failure. IndexManager reads/writes JSON embedding indexes with locking. SearchEngine performs cosine similarity search with keyword fallback. All unit tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire embedding generation into engines and upgrade twining_query</name>
  <files>
    src/engine/blackboard.ts
    src/engine/decisions.ts
    src/tools/blackboard-tools.ts
    src/server.ts
    src/storage/init.ts
  </files>
  <action>
    **Update `src/storage/init.ts`:**
    - Add `embeddings/` directory creation in `ensureInitialized()` — create `.twining/embeddings/` alongside existing directories
    - Add `models/` to the `.twining/.gitignore` template (model cache files should not be committed)

    **Update `src/engine/blackboard.ts`** — Add embedding generation on post:
    - Add optional `embedder: Embedder | null` and `indexManager: IndexManager | null` constructor parameters (null = no embeddings, for backward compatibility)
    - In `post()`, after appending to store, if embedder is not null:
      - Generate embedding: `const vector = await embedder.embed(entry.summary + ' ' + entry.detail)`
      - If vector is not null, store in index: `await indexManager.addEntry('blackboard', entry.id, vector)`
      - Set `entry.embedding_id = entry.id` on the stored entry (embedding_id matches the entry id)
      - Wrap in try/catch — embedding failure must NEVER prevent the post from succeeding
    - Add `async query(query: string, options?: { entry_types?: string[], limit?: number }): Promise<{ results: { entry: BlackboardEntry, relevance: number }[], fallback_mode: boolean }>` method:
      - If no searchEngine, return empty results
      - Load all entries from store, delegate to `searchEngine.searchBlackboard()`
      - Default limit: 10 (per CONTEXT.md locked decision)
    - Add `searchEngine: SearchEngine | null` constructor parameter

    **Update `src/engine/decisions.ts`** — Add embedding generation on decide:
    - Add optional `embedder: Embedder | null` and `indexManager: IndexManager | null` constructor parameters
    - In `decide()`, after creating decision and cross-posting to blackboard:
      - Generate embedding: `const vector = await embedder.embed(decision.summary + ' ' + decision.rationale + ' ' + decision.context)`
      - If vector is not null, store: `await indexManager.addEntry('decisions', decision.id, vector)`
      - Wrap in try/catch — embedding failure must NEVER prevent decide from succeeding

    **Update `src/tools/blackboard-tools.ts`** — Upgrade `twining_query` tool:
    - The existing tool registration for `twining_query` (if it exists as a stub or placeholder) should now route to `blackboardEngine.query()`:
      - Input: `{ query: string, entry_types?: string[], limit?: number }` (matching spec section 4.1 twining_query)
      - Output: `{ results: { entry: BlackboardEntry, relevance: number }[], fallback_mode: boolean }`
    - If `twining_query` is not yet registered, add it with proper Zod schema matching the spec

    **Update `src/server.ts`** — Wire embeddings into the server:
    - Import `Embedder`, `IndexManager`, `SearchEngine` from `src/embeddings/`
    - Create embedder: `const embedder = new Embedder(twiningDir)` (lazy, no init cost)
    - Create indexManager: `const indexManager = new IndexManager(twiningDir)`
    - Create searchEngine: `const searchEngine = new SearchEngine(embedder, indexManager)`
    - Pass embedder, indexManager, searchEngine to BlackboardEngine and DecisionEngine constructors
    - No changes needed to the MCP server setup itself — tools are already registered, just the engines gain new capabilities

    **Note on backward compatibility:** All new constructor parameters are optional/nullable. Existing tests should continue to pass without modification (engines work without embeddings, just skip embedding generation).
  </action>
  <verify>
    ```bash
    npm test -- --run
    npx tsc --noEmit
    ```
    All existing tests still pass (backward compatibility). New embedding generation is wired in but doesn't break existing functionality. TypeScript compiles cleanly.
  </verify>
  <done>
    Blackboard posts and decisions automatically generate embeddings (with silent failure). `twining_query` performs semantic search (or keyword fallback). Server creates embedder/indexManager/searchEngine and wires them into engines. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `npm test` — all tests pass (existing + new)
2. `npx tsc --noEmit` — TypeScript compiles without errors
3. `npm run build` — builds to dist/ successfully
4. Verify `twining_query` tool is registered in server with correct Zod schema
5. Verify embedder does NOT initialize until first embedding operation
6. Verify that setting `SKIP_ONNX=1` (or mocking pipeline failure) causes graceful fallback to keyword search
7. Verify embedding index files are written to `.twining/embeddings/`
</verification>

<success_criteria>
- All EMBD-* and BLKB-03 requirements addressed
- Embedder is lazy-loaded (EMBD-02): no ONNX loading at server startup
- Embedder falls back gracefully (EMBD-03): keyword search when ONNX unavailable
- Embeddings generated for every entry/decision (EMBD-04): hooks in both engines
- Semantic search works (BLKB-03, EMBD-01): twining_query returns ranked results
- All tests pass, TypeScript compiles, builds to dist/
</success_criteria>

<output>
After completion, create `.planning/phases/02-intelligence/02-01-SUMMARY.md`
</output>
